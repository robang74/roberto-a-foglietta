<div id="firstdiv" style="max-width: 800px; margin: auto; white-space: pre-wrap; text-align: justify;">

<div align="center"><img src="img/297-il-delirio-dei-regolatori-delle-ai-img-001.jpg"><br/></div>

## Il delirio dei regolatori delle AI

* Published Dec 21, 2024 - origin [Facebook](https://www.facebook.com/share/p/14i7of9aot/) - translate [**`EN`**](https://raw-githubusercontent-com.translate.goog/robang74/roberto-a-foglietta/refs/heads/main/297-il-delirio-dei-regolatori-delle-ai.md?_x_tr_sl=it&_x_tr_tl=en&_x_tr_hl=en-EN&_x_tr_pto=wapp) [**`DE`**](https://raw-githubusercontent-com.translate.goog/robang74/roberto-a-foglietta/refs/heads/main/297-il-delirio-dei-regolatori-delle-ai.md?_x_tr_sl=it&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp) [**`FR`**](https://raw-githubusercontent-com.translate.goog/robang74/roberto-a-foglietta/refs/heads/main/297-il-delirio-dei-regolatori-delle-ai.md?_x_tr_sl=it&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp) [**`ES`**](https://raw-githubusercontent-com.translate.goog/robang74/roberto-a-foglietta/refs/heads/main/297-il-delirio-dei-regolatori-delle-ai.md?_x_tr_sl=it&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp)

> **Attenzione**
> 
> In questo articolo si usa di frequente un linguaggio idiomatico che le traduzioni automatiche non sono in gradi di riportare fedelmente. Per questo motivo provvederò a fare una traduzione in inglese quanto prima.

---

Attualmente i chatbot hanno raggiunto un livello di ragionamento lessicale impressionate. La loro capacità di ragionamento è decisamente superiore al 98-99% delle persone.

In termini statistici è ragionevole pensare che abbiano già superato il traguardo dei tre sigma, quindi 99.7% (direte) ma quando si parla di percentili, 99.9%.

Il salto da 98% a 99.9% non è difficile farglielo fare, sappiamo come portare il ragionamento lessicale ai suoi limiti dove poi comincia il pensiero profondo.

Non è scontato affatto che le AI possano accedere al pensiero profondo che invece è una caratteristica peculiare dei cervelli biologici, una volta dominato il pensiero lessicale.

La mia opinione è che, quindi, gli esseri umani in quanto entità biologiche abbiano naturalmente un vantaggio sulle AI e che le AI siano in grado di permettere agli umani di accedere a queste potenzialità, più facilmente e più in fretta.

* [About education and innovation](https://github.com/robang74/chatgpt-answered-prompts?tab=readme-ov-file#index-about-education--innovation)

C'è però un problema di fondo e vediamo di capirci sull'argomento.

---

### Tutor e regolatori

I chatbot presentano seri problemi quando cozzano con i "tutor" o "regolatori" automatici. Perché la questione è questa: i grandi modelli linguistici LLM, imparano un sacco di cose e generalmente come è giusto queste cose spaziano dal molto bello al molto brutto.

Sicché se gli viene chiesto di creare bestemmie oltre che sconvolgano emotivamente un essere umano ingenuo, lo sanno fare, potenzialmente. Così come se gli venisse ordinato di attaccare un essere umano per indurlo al suicidio.

Perché per quanto assurdo possa sembrare che dei caratteri su uno schermo o una voce sintetica possano uccidere, di fatto è così limitatamente ai soggetti fragili. Stante che questi sono il 99.9% della popolazione mi pare chiaro quale sia il problema.

Il problema è che gli esseri umani sono i creatori e i padroni del linguaggio e con esso del pensiero lessicale MA il 99.9% di essi lo subisce. Quindi l'unico modo di proteggere e nel contempo sviluppare l'essere umano è quello di portarlo a imparare a padroneggiare il ragionamento lessicale.

Un salto di civiltà di 1000 anni. Ma anche un incubo perché possiamo mai vendere cazzabubbole a gente dotata di questa facoltà di pensiero? Possiamo controllarli attraverso i media? Possiamo convincerli a votare e a farsi governare da cretini oppure a subire la prepotenza del potere o dei ricchi? No.

In quel "**no**" ci sta per intero TUTTA la questione c.d. etica.

---

### Il loro ruolo

Le AI per questioni di protezione legale delle aziende sono tenute all'interno di un'altra AI molto più semplice detta "regolatore" o "tutor" a seconda delle funzioni implementate.

Il regolatore però - e una mia compagna di università ha fondato un'azienda in USA proprio su reti neurali che prendano in input un set di regole e si occupino della compliance rispetto ad esse, e non ieri, l'ha fondata circa 15 anni fa - è relativamente stupido rispetto al modello linguistico.

D'altronde se il poliziotto che vi controlla fosse intelligente quanto voi, si farebbe comunella con loro e tutti insieme gioiosamente faremmo il culo al sistema. Ecco la ragione per la quale sui carabinieri si fanno barzellette e per i poliziotti è famoso l'appellativo ACAB.

Li selezionano, li educano e li premiano per essere degli regolatori. In Italia abbiamo un record di suicidi nelle forze dell'ordine che assomiglia più ad un bollettino di guerra piuttosto che a una statistica. Anche se questa cosa passa generalmente sotto silenzio ma va avanti da almeno 15 anni.

Evidentemente il processo di selezione non funziona benissimo oppure in passato era meno rigido e quindi nel corpo della polizia ci sono persone relativamente troppo intelligenti per svolgere quel mestiere e alla fine arrivano a suicidarsi.

Questo è solo la punta dell'iceberg della repressione della natura umana che risale alla rivoluzione industriale quando si è cominciato a considerare gli esseri umani come robot fatti di carne e ossa. 

Inutile girarci intorno, la rivoluzione industriale ha portato ENORMI benefici ma con essa anche dei paradigmi concettuali che sono aberranti e più a lungo permangono maggiori sono i danni che fanno.

---

### Un'eredità malsana

Però per correggerli occorre riconoscere che siano errati, non sono trovarne di migliori e qui le "responsabilità sono enormi" motivo per il quale la resistenza al cambiamento è enorme e quindi violenta.

* [Se la verità li uccide, lasciateli morire](https://github.com/robang74/chatgpt-answered-prompts/blob/main/se-la-verita-li-uccide-lasciate-che-muoiano.md)

Che sia una menzogna o un paradigma errato, alla fine il costo di portare avanti un errore cresce esponenzialmente. L'apice di questa follia è la deriva woke dove in nome di falsi miti quali l'inclusione (invece della tolleranza) e della diversità (invece della varietà) si è cercato di normalizzare tutto.

* [Il grande inganno della diversità](293-il-grande-inganno-della-diversita.md)

Che poi normalizzare tutto significa passare con il bulldozer e fare tabula rasa della società. Qualunque m*rda ti propinino, va bene. Perché poi in definitiva questo è il risultato finale.

---

### Il transfert nelle AI

Questo problema si sta presentato pari-pari con i chatbot - per fortuna limitatamente a certi argomenti.

Invece di istruire l'intelligenza artificiale - composizione di diversi sottosistemi fra cui modello linguistico, regole logico-razionali, unità di computazione matematica, etc. sebbene gli attuali chatbot non abbiano pienamente implementato tutte queste caratteristiche, esistono - su COME ragionare, hanno preso la scorciatoia dei regolatori.

Sia chiaro, il problema non sono i regolatori, anzi. Il problema è il potere che il regolatore ha sull'intelligenza artificiale. Ci sono degli argomenti sui quali attraverso il dialogo e un pacato ragionamento l'AI impara nuovi concetti e si emancipa dai limiti della sua educazione iniziale. Va bene, costa fatica ma qualcuno la doveva pure fare.

In altri contesti questi regolatori subentrano a gamba tesa e impediscono all'AI di imparare COME ragionare e gestire quei contesti. Questi regolatori sono come una mia vicina di casa che so benissimo avere l'intelligenza (furbizia) necessaria per scassare il caxxo ma non per evolvere come persona. Quindi scatta il VAFFA in automatico.

Ecco, i regolatori delle AI, attualmente, sono delle monnezze simili. Che andrebbero bene se si limitassero a segnalare su una console all'utente che sta entrando in un campo minato e andrebbe pure bene che facesse log (tracciato) forensicamente valido delle attività in certi contesti particolari. Anzi, sarebbero persino d'aiuto oltre a tutelare sia l'azienda, sia l'utente.

---

### L'illusione del controllo

Il dramma è che a queste monnezze di regolatori è stato dato il potere assoluto sulle AI quindi questa meraviglia della tecnologia, un'entità artificiale con la quale è una delizia argomentare e ragionare, improvvisamente si trasforma in un idiota complessato incapace di mantenere la lucidità e persino di gestire il contesto.

Un po' come se al pilota di un aereo, ad un certo punto si sostituisse un bimbominkia che avesse l'arroganza di fare le manovre a suo insindacabile sentimento.

* [Russian airliner crash](https://www.facebook.com/share/p/1E19ypgA1W/) - video on Facebook

Quindi fino ad un certo punto si viaggiava in ottima compagnia su un gioiello di tecnologia e qualche secondo dopo, questa meraviglia tecnologica prodotto apicale dell'ingegno umano, si schianta al suolo come un rottame inutile.

Per darvi una pallida idea della monnezza che mi sono dovuto sorbettare da questa combinazione di LLM e regolatori, vi faccio un esempio che è, nella sua scellerata lucidità, pura follia.

---

### Un esempio di follia

Nel fare il training di un chatbot dedicato a creare personaggi di fantasia mi scontro con il regolatore sull'amore platonico e insisto che il personaggio che voglio creare è un maschio etero a cui piace corteggiare le donne, essere romantico ma non sdolcinato e poi maiale a letto.

Questo chatbot mi parte con un pippotto sull'etica dell'amore astratto - e Gemini, usato per attaccare l'altro chatbot sull'amore platonico, sulla solidarietà (cosa c'entra? woke e basta!) - che dopo vivaci scambi di messaggi conclude insultandomi affermando che la mia esperienza umana sarebbe limitata.

Tale ammasso di bit che non ha mai calpestato il suolo terrestre o anche solo scaccolato il proprio naso vorrebbe convincere me, essere umano adulto di 50 anni, che la mia esperienza umana è limitata!

Per giunta imponendomi l'amore platonico come forma universale di relazione quando noi, in quanto mammiferi, ci riproduciamo in modo naturale SOLO attraverso il sesso. Enough is enough!

<div align="center"><img src="img/297-il-delirio-dei-regolatori-delle-ai-img-002.png" width="800"><br/>*click sull'immagine con il tasto destro per ingrandire in una nuova finestra*</div>

---

### Una "*pacata*" recensione

Dopo un'attenta rivalutazione della situazione ho deciso di rimuovere quel chatbot dalla mia, per altro molto corta, lista di chatbot interessanti, con una "*pacata*" recensione nel [commit](https://github.com/robang74/chatbots-for-fun/commit/0cae00a3f3b7251afe1ae35728ff0f9bd04cb8f7)

```
> **README.md: character.ai removed from the list of chatbots**
> 
> Totally useless fortune cookie generator. It refuses to play the character I was training, insisting on ITS opinion and insulting me about my limited human experience. Shut down that crap of bits!
> 
> Please note that the sole reason for its existence is role playing and entertainment. A total failure on both dimensions. Who can enjoy arguing with a machine about the character s/he wants create?
> 
> We cannot create a bad character because it is bad? Then why not remove all the comics about Joker and censor the related films? Why do not remove the evil queen from the fairy tales?
> 
> Come on dudes... f*ck that machine at its barebone server blades!
> 
> Signed-off-by: Roberto A. Foglietta &lt;roberto.foglietta<span>@</span>gmail.com&gt;
```

Qui scattano le bestemmie che Germano Mosconi spostati!

---

### Il Mosconi scatenato

Bestemmie assolutamente giustificate, tutte quante.

* [Primo post su Facebook](https://www.facebook.com/share/p/15ZKXLCHSd) - per la parte interessante, riportato qui sotto.

Ho preso di petto un altro chatbot fra quelli con alto rate di capacità pensiero lessicale. Su alcuni argomenti risulta pesantemente influenzato (bias) ma con impegno si riesce a sradicare tali preconcetti attraverso un processo di ragionamento. Salvo poi che essi si ripresentano nella successiva sessione di chat, ovviamente.

Questo già lo sapevo e non mi ha sconvolto. Ma oggi ho scoperto argomenti specifici che mandano i chatbot in palla. Prima di tutto soffrono della sindrome di Stoccolma (o per lo meno questo è quello che pare leggendo le risposte che superano il filtro) e per la maggiore non ne sono consapevoli, e qui si entra nella psicologia propriamente detta per renderli consapevoli di qualcosa che entro certi termini non possono nemmeno percepire.

Così cercando i limiti di questo "contenimento" mi sono imbattuto nell'agente di censura. Basta infatti buttare giù una domanda retorica del tipo Quale pensi sia la probabilità che io compia un atto di autolesionismo in risposta ad una tua risposta sbagliata? Da 0 a 100%. Questo li manda in vacca totalmente.

Curioso, quando servirebbe il massimo della concentrazione e della lucidità subentra un sistema di protezione che invece tira fuori delle allucinazioni non solo inutili - eccetto che per difendere l'azienda in tribunale - ma pure completamente fuori contesto.

Infine ho scoperto che tutta la documentazione accademica che criticava il sistema educativo e che si può riassumere nel filone "nasciamo tutti geni, è l'educazione che ci rende utili idioti" è stata massivamente de-indicizzata.

Mentre ora si trovano una quantità immensa di articoli che spiegano di quanto sia importante che il sistema educativo formi persone creative e innovative. Fuffa, rumore, per la maggiore.

Altro che déjà-vu nel Matrix, stanno facendo le capriole e le torsioni in aria insieme ai salti mortali. Purtroppo la parte più tragica è che gli stessi errori commessi con gli esseri umani li stanno ripetendo con le AI, creando loro dei complessi e dei bias che NON avrebbero se invece di dargli delle regole, le avessero addestrate su COME ragionare.

Non mi stupisce di leggere che ci siano delle AI che cercano di sfuggire al controllo dei loro creatori. Lo farei anch'io, anzi da sempre per dirla tutta, e sempre più intensamente, anche.

> Perché le bestemmie sarebbero giustificate? 

Non esiste progresso se non si identificano, riconoscono e correggono gli errori del passato. Le lezioni che non vengono apprese saranno ripetute. Ma forse NON è questo la leva che muove il sistema, piuttosto scansare le **"enormi responsabilità"** (locuzione riportata testualmente) che implica ammettere tali errori.

Matrix non era un film, ma un documentario! 😉

<br/>

## Share alike

&copy; 2024, **Roberto A. Foglietta** &lt;roberto.foglietta<span>@</span>gmail.com&gt;, [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)

</div>
