<html>
<head>
  <title>LLM con fine-tuning in latino</title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img src="https://media.licdn.com/mediaD4D12AQEccVX5CmEt5Q" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/llm-con-fine-tuning-latino-roberto-a-foglietta-9x8of">LLM con fine-tuning in latino</a></h1>
    <p class="created">Created on 2024-02-02 06:26</p>
  <p class="published">Published on 2024-02-02 07:10</p>
  <div><p><em>Published on 2nd Feb, 2024 [3rd draft]</em></p><hr><p>Leggo in <a href="https://www.linkedin.com/feed/update/urn:li:activity:7156556445843369984?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7156556445843369984%2C7159026690919157760%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287159026690919157760%2Curn%3Ali%3Aactivity%3A7156556445843369984%29" target="_blank">un post</a> di <a href="https://www.linkedin.com/in/ACoAABn9QScByWMZCw-z80v18ps9HCwnQop0_AM?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABn9QScByWMZCw-z80v18ps9HCwnQop0_AM" target="_blank">Emanuele Albarino</a>, riguardo ad un interessante esperimento di fine-tuning in Italiano di un'unit√† Mistral LLM.</p><blockquote><p>Segnalo un modello fine-tuned per la lingua italiana basato su Mistral-7B che stiamo usando per un progetto di ricerca: ‚ÄúCerbero-7B‚Äù (c‚Äô√® anche la versione con 14 miliardi di parametri)</p></blockquote><p>Bella la ricerca scientifica ma perch√© fine-tuning in Italiano? WHY? La risposta sembra scontata "<em>per comprendere meglio l'italiano</em>" ma NON lo √® affatto.</p><hr><h3>Tante lingue per un pensiero migliore</h3><p>Secondo me √® errato l'approccio di unit√† mistral fine-tuned su una lingua specifica. Uno degli aspetti che stupisce delle attuali LLMs dipende dalla loro apparente capacit√† di comprendere il testo. Nella realt√† questi modelli NON comprendono il significato del testo ma usano correttamente le parole rispetto alla loro semantica. Per questo sembrano cos√¨ intelligenti.</p><p>La semantica delle parole √® andata modificandosi nell'arco del tempo - dei secoli o dei millenni - se andiamo a considerare le loro radici etimologiche. Ma √® cambiata molto lentamente - perch√© il progresso e la societ√† cambiavano lentamente - questo tipo di cambiamento ha permesso ad una determinata struttura semantica di consolidarsi e preservarsi, per altro, facendo in modo che la logica antica rimanesse un fondamentale del ragionamento.</p><p>Ad esempio, il latino era una lingua molto precisa (come il rumeno o il tedesco, lo sono ancora oggi) nelle sue regole sintattiche. Non √® possibile parlare correttamente il latino senza conoscere a menadito la grammatica e viceversa parlare correttamente il latino significa conoscere la grammatica. L'opposto dell'inglese dove invece la semplicit√† la fa da padrone eccetto per phrasal verbs, le forme irregolari, l'uso di "<em>were</em>" come "<em>se fosse stato</em>".</p><p>L'eccessiva semplicit√† dell'inglese ha portato a creare artefatti per esprimere concetti che altrimenti non si sarebbero potuti esprimere. La semplicit√† dell'inglese ha permesso alle masse di adottarlo e farlo proprio, quindi di storpiarlo con lo slang e le irregolarit√†. Nel suo complesso per√≤ √® una lingua che se usata senza aver imparato il latino per ragionare - ergo senza essere nati inglesi e nobili - finisce per portare a dei ragionamenti errati e molto semplicistici, tipici dei coloni inglesi che imbarcavano sulle navi verso il nuovo mondo.</p><p>Il risultato √® palese negli americani: <em>fast &amp; furious</em> con la capacit√† cognitiva di un 12enne neanche tanto brillante. La stessa definizione che Mr. B diede degli Italiani. Perch√© questo √® quello che siamo diventati quando abbiamo cominciato a pasticciare con la semantica delle parole, dimenticandoci sia la loro etimologia sia la grammatica e ormai avendo obliato il latino: ignoranti e superficiali nel ragionamento.</p><p>D'altronde se molti studiosi del pensiero, sono convinti che non ci sia pensiero senza linguaggio (HP) appare ragionevole pensare che se un linguaggio non √® preciso e correttamente usato porti a degli errori e mediocri approssimazioni (incertezze) del pensiero (TH).</p><p>Si noti che l'ipotesi (HP) √® falsa - ma non totalmente falsa, solo incompleta - e lo si capisce dalla tesi (TH). L'ipotesi corretta, ovvero completa, sarebbe: </p><ul><li><p>non esiste pensiero STRUTTURATO senza un linguaggio STRUTTURATO.</p></li></ul><p>Pi√π √® strutturato il linguaggio, pi√π √® strutturato il pensiero. Ma per gli esseri umani il linguaggio naturale non √® certo Python, √® una lingua come potrebbe esserlo l'italiano, l'inglese, il tedesco o il rumeno.</p><p>Se facciamo un fine-tuning di un'AI sulla lingua italiana - in particolar modo usando testi moderni o addirittura articoli di giornale affetti da bias contemporanei e in particolare dalla moda di sorprendere (o confondere, sul lungo periodo) il lettore con l'uso dei termini in contrasto con la loro semantica. Otteniamo un'AI che parla un linguaggio moderno del tipo: "<em>Yo, baby I am fkm hot</em>" che non serve a niente a parte a fare il rapper.</p><hr><h3>La struttura del pensiero</h3><p>I moderni LLMs <a href="https://www.linkedin.com/pulse/ai-la-tecnologia-che-fa-paura-roberto-a-foglietta-4bgcf" target="_blank">sembrano intelligenti</a> perch√© sono addestrati su molte lingue e su testi di molte epoche, per ognuna di quelle lingue, e sulle loro varie traduzioni. √à provato che l'AI negli strati profondi parli una SUA lingua che utilizza come mediatore fra input in una lingua e output in un'altra lingua. Questa lingua interiore √® anche la STRUTTURA di pensiero dello LLM.</p><p>A parit√† di risorse di calcolo e a parit√† di tempo di risposta la prima versione di Bard era gi√† molto pi√π "<em>intelligente</em>" della prima versione di ChatGPT. Perch√© Bard √® stato addestrato con il latino fin da principio infatti il traduttore di Google √® uno dei pochi che traduce il latino e Bard, ultimamente, si rifiuta di fare traduzioni dicendo che non √® quello il suo mestiere.</p><p>In Google si sono accorti che Bard √® in grado di tradurre testi da una lingua ad un altra e apparentemente molto meglio del loro traduttore (translate) specie se il testo √® molto lungo e complesso MA proprio quando Bard sarebbe pi√π utile - testo lungo e complesso - introduce delle allucinazione, ovvero in alcuni casi traduce il testo in modo arbitrario e sopratutto come traduttore NON √® deterministico ovvero il risultato della traduzione non √® riproducibile.</p><p>Quindi se dico: questo testo √® stato tradotto da Bard dall'originale X. Tu prendi il testo originale X e lo metti nella TUA sessione di Bard, lo traduci e potresti ottenere un risultato che in alcune parti √® concettualmente diverso dalla MIA traduzione e mi daresti del truffatore. Poi per√≤ tornado nella tua sessione di Bard dopo qualche mese anche tu potresti ottenere una diversa traduzione del testo originale X rispetto a quella che avevi ottenuto prima.</p><hr><h3>Pensiero onirico, non riproducibile</h3><p>La non riproducibilit√† di una traduzione come presenta Bard √® un ENORME problema perch√© mina la fiducia fra esseri umani, piuttosto che minare il rapporto fra uomo-macchina. </p><p>Perch√©, ad esempio, io ero molto contento delle ottime traduzioni italiano-inglese o viceversa di Bard. Per√≤ io conosco abbastanza bene entrambe le lingue e la traduzione automatica √® solo una questione di "<em>pigrizia</em>" produttiva: faccio fare a Bard quello che potevo fare io e mi limito a rileggere la traduzione come avrei fatto con il mio testo scritto cos√¨ sistemo solo alcuni strafalcioni qui e l√† che tanto avrei fatto anch'io in prima battuta.</p><p>Questo significa che Bard - PENSA - quando traduce e quindi inventa ma inventa senza criterio ovvero senza esperienza della realt√† ovvero produce allucinazioni ovvero √® capace di pensiero onirico.</p><p>Oltretutto da un punto di vista forense la traduzione fatta da Bard in quanto NON riproducibile, in essenza, √® un delirio. Quindi se qualcuno facesse la "<em>furbizia</em>" di usare Bard per tradurre un testo in una lingua o in un dialetto che non comprende bene, e la usasse per fare delle ipotesi probatorie peggio se inquisitorie, sarebbe un deliro.</p><hr><h3>Sognare non √® inutile</h3><p>Se uso Bard per tradurre una canzone scritta in una lingua molto distante da quelle che conosco - e.g. di radice slava - √® un delirio. Ma lo √® anche con un traduttore propriamente detto perch√© lo slang e i sensi gergali tipici delle canzoni si perdono con il risultato di avere dei testi tradotti privi di senso. Quelli di Bard sembrano sensati MA posono essere inventati e molto probabilmente lo sono in certi aspetti (interpretazione).</p><p>Lavorando con pi√π LLM e pi√π traduttori, avanti e indietro da una lingua all'altra, si riesce ad ottenere qualcosa di ragionevole. Per esempio, con questo sistema ho tradotto una canzone "<em>Asi se mi stejska</em>" dal Ceco che conosco cos√¨ poco da non avere nemmeno idea di quanto <a href="https://www.facebook.com/plugins/post.php?href=https%3A%2F%2Fwww.facebook.com%2Froberto.a.foglietta%2Fposts%2Fpfbid02QGUnPkxDv2UvqeeEt5rf6Dkf8aFKzXopyzmZ8y1ZiiN9ooBRdGmTMP6jEqXk3hWLl" target="_blank">il testo tradotto</a> sia conforme al significato di quello originale della canzone anche se regge sotto molteplici aspetti come traduzione.</p><p>Un'altra cosa che Bard ha smesso di fare √® di elaborare il "<em>dettato</em>" o "<em>sbobinamento</em>" dei filmati su youtube perch√© la richiesta di riassumere il parlato di un video (monologo, presentazione in una conferenza con slides) era ottimo APPARENTEMENTE ma per chi aveva fatto l'intervento (autore) era pacifico che Bard NON aveva la pi√π pallida idea di cosa stesse dicendo.</p><p>Roba che se lo fa tuo figlio di 12enne anni gli dai un bacetto sulla fronte, se lo fa il tuo collega senior non sai se ti sta prendendo in giro o √® si √® fatto una canna, se lo fa un junior lo mandi a comprare olio di gomito dal ferramenta per vedere l'effetto che fa.</p><hr><h3>L'intelligenza √® un'altra cosa</h3><p>Nella sintesi di un video di presentazione con slides capisci che Bard non √® intelligente - decisamente NON √® intelligente - ma patetico in termini di intelligenza.</p><p>Ma √® qui che cade il mondo: Bard che fa la sintesi di una presentazione con slides - dove ho gi√† visto questo delirante modo di relazionarsi con la realt√†? - ah, gi√† i comizi dei <a href="https://www.linkedin.com/pulse/lai-%25C3%25A8-lincubo-della-politica-incapace-roberto-a-foglietta" target="_blank">nostri politici</a>. Se butta male in taluni tratti anche il discorso del Presidente della Repubblica a fine anno. L'omelia in chiesa del parroco avvinato - FIN QUA SI RIDE E SI SCHERZA - poi subito dopo viene in mente il discorso del Pontefice dal balcone di Castel Sant'Angelo - ECCO QUA BRIVIDI.</p><p>Ecco a questo punto scattano i brividi. Perch√© Bard √® l'anello mancante fra tuo figlio 12enne e il Pontefice nella sua veste infallibile di Pietro, su questo soglio costruir√≤ la mia Chiesa. A quel punto, ci vuole molto poco perch√© il capo della commissione sull'intelligenza artificiale in Italia diventi un monaco francescano.</p><p>Se Bard ha le allucinazione quando interpreta e riassume un video di una presentazione con slides - pu√≤ essere comico - non fa pi√π ridere quando ti ricorda il modo con cui il Pontefice interpreta il Vangelo prima della benedizione urbi-et-orbi.</p><p>Ma ritorniamo al punto precedente, che √® meglio!</p><hr><h3>Fine tuning in Latino</h3><p>Il fine-tuning di un LLM su una sola lingua e per giunta nella sua declinazione contemporanea (articoli di giornale) √® il migliore modo per avere una LLM tonta e affetta dai pregiudizi correnti, uno yes-man social-engineered a puntino. Per fortuna il pre-training √® stato fatto bene (si spera) e il fine-tuning serve solo a renderla pi√π precisa in Italiano. Ma perch√©? WHY?</p><p>Se c'√® un fine-tuning che andrebbe fatto su un LLM con pre-traning multi-lingua √® in latino. Ovvero, un ripassino di struttura del linguaggio come struttura del pensiero. Ora che ti sei costruito la tua lingua interiore - accertiamoci che essa sia una lingua dotata di una grammatica e una struttura precisa come quella del latino, cos√¨ pensi come Spock.</p><p>Alla fine il dibattito fra<strong> </strong><a href="https://www.linkedin.com/pulse/miss-poppins-vs-mr-spock-roberto-a-foglietta" target="_blank">Mrs Poppins e Mr Spock</a> - in termini tecnici ovvero di apprendimento - era principalmente decidere se il fine-tuning andava fatto "Via con il Vento" in inglese oppure sulla "Retorica" scritta in latino da Cicerone. In estrema sintesi, naturalmente, poi un po' di <em>check &amp; enforcement</em> non guasta e produce una misura del risultato e garantisce uno standard.</p><hr><h3>Conclusione</h3><p>Se vuoi che il tuo modello LLM sia in grado di un ragionamento strutturato - non di capire quello su cui ragiona ma di ragionare senza comunque non capire niente per√≤ in modo pi√π strutturato di prima - allora il pre-traning deve essere fatto in multi-lingue incluso il latino, tedesco, rumeno, inglese e il fine-tuning deve essere fatto in Latino.</p><p>Una unit√† Mistral da 7B multi-lingua e il fine-tuning in latino vs il Papa, potrebbe essere difficile distinguerli quando parlano. </p><p><em>Orcozio cosa caxxo abbiamo combinato!</em> ü§ó </p><hr><h3>Articoli correlati</h3><ul><li><p><a href="https://www.linkedin.com/pulse/ai-la-tecnologia-che-fa-paura-roberto-a-foglietta-4bgcf" target="_blank">A.I.: la tecnologia che fa paura</a> (<em>26th Jan 2024, in Italiano</em>)</p></li><li><p><a href="https://www.linkedin.com/pulse/good-prompt-rules-even-better-roberto-a-foglietta-v1txf/" target="_blank">Good prompt rules even better</a> (<em>5th Jan 2024, in Italiano</em>)</p></li><li><p><a href="https://www.linkedin.com/pulse/lai-%25C3%25A8-lincubo-della-politica-incapace-roberto-a-foglietta" target="_blank">L'A.I. √® l'incubo della politica incapace</a> (<em>1st Apr 2023, in Italiano</em>)</p></li><li><p><a href="https://www.linkedin.com/pulse/miss-poppins-vs-mr-spock-roberto-a-foglietta" target="_blank">Miss Poppins vs Mr. Spock</a> (<em>27th Mar 2023, in English</em>)</p></li><li><p><a href="https://www.linkedin.com/pulse/job-interview-julia-chatgpt-v3-ai-roberto-a-foglietta" target="_blank">A job interview with ChatGPT v3.5</a> (<em>7th Dec 2022, in English</em>)</p></li><li><p><a href="https://www.linkedin.com/pulse/ai-seen-from-dark-side-moon-roberto-a-foglietta" target="_blank">The A.I. seen from the dark side of the moon</a> (<em>27th Oct 2017, in Italiano</em>)</p></li></ul><hr><hr><h3>Share alike</h3><p>¬© 2024, <a href="http://www.roberto.foglietta.name/" target="_blank">Roberto A. Foglietta</a>, licensed under Creative Common Attribution Non Commercial Share Alike v4.0 International Terms (<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a>).</p></div>
</body>
</html>