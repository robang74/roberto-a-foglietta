<html>
<head>
  <title>Paradosso di Fermi e Singolarità A.I.</title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img src="https://media.licdn.com/mediaC5612AQEf76WTl0ExYw" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/paradosso-di-fermi-e-singolarit%C3%A0-ai-roberto-a-foglietta">Paradosso di Fermi e Singolarità A.I.</a></h1>
    <p class="created">Created on 2017-10-16 16:50</p>
  <p class="published">Published on 2017-10-16 17:32</p>
  <div>
  <p><em>Published on October 16, 2017</em></p> 
  <h2>Premessa</h2> 
  <p>La lettura di questo articolo consiglierebbe la lettura di questo come propedeutica</p> 
  <ul> 
   <li><a href="https://www.linkedin.com/pulse/limportanza-del-tcmo-roberto-a-foglietta/" target="_blank">L'importanza del TCMO</a> (9 ottobre 2017)</li> 
  </ul> 
  <p>perché alcuni concetti descritti in precedenza verranno utilizzati qui, ad esempio:</p> 
  <ul> 
   <li>TCMO: Total Cost of a Mistake Ownership cioè il costo totale della perseveranza in errore a carico di un attore e/o di un decisore (owner).</li> 
   <li>TCI: Total Cost of Innovation cioè il costo totale di implementare un cambiamento.</li> 
  </ul> 
  <h2>Il paradosso di Fermi in termini di TCMO</h2> 
  <p>Il paradosso di Fermi potrebbe evolvere in un teorema di confinamento dell'evoluzione.&nbsp;</p> 
  <ul> 
   <li>Le specie che evolvono in equilibrio con l'ambiente (TCMO &lt;&lt; TCI) non sono interessate a ciò che sia esterno al loro ambiente.&nbsp;</li> 
   <li>Le specie che invece evolvono fuori dall'equilibrio raggiunto il punto di non ritorno (TCMO &gt;&gt; TCI) condannandosi all'estinzione di massa.&nbsp;</li> 
  </ul> 
  <p>In entrambi i casi, l'evoluzione rimarrebbe confinata nell'ecosistema di origine.&nbsp;</p> 
  <ul> 
   <li>La probabilità che una specie evolva e si mantenga, durante il suo sviluppo tecnologico, sul filo del rasoio (TCMO ~ TCI) tendono a zero sul lungo periodo [¹] perciò ad un certo punto una delle condizioni sopra si manifesta come dominante.</li> 
  </ul> 
  <p>[¹] Nell'elaborare il suo paradosso, Fermi prese in considerazione che l'età dell'universo fosse circa 8 miliardi, di cui 4½ per lo sviluppo di pianeti abitabili, 3½ per lo sviluppo della vita e 10÷100 milioni di anni per sviluppare una civiltà capace di affrontare l'esplorazione spaziale.</p> 
  <p>La teoria del TCMO confermerebbe il paradosso di Fermi per il quale ad un certo punto qualsiasi civiltà che si sia evoluta lo abbia fatto attraverso i medesimi meccanismi di selezione naturale. Tali meccanismi avranno sviluppato gli stessi pregiudizi cognitivi che avranno permesso alla civiltà di raggiungere un certo grado di progresso utile all'estinzione di massa.</p> 
  <p>Per analogia: se mettiamo una scimmia alla guida di un'auto di formula uno, il risultato è scontato. Perché questa analogia è attinente?</p> 
  <h3>Analisi della situazione globale alla luce del TCMO</h3> 
  <p>La scienza e la tecnologia sono fenomeni cumulativi, la nostra capacità media di utilizzare questo know-how invece no! Essa progredisce meno che linearmente perché la generazione successiva riceve un'educazione basata - non su quei criteri che gli saranno utili per il futuro - ma secondo i criteri selezionati dalla precedente generazione.</p> 
  <p>L'unica speranza di uscire dal paradosso di Fermi è che l'accelerazione tecnologica sia così rapida che la generazione N+1 consideri la generazione N degli inutili idioti. condizione necessaria, non sufficiente. Infatti, bisognerebbe che la generazione N+1 fosse in grado di sviluppare gli strumenti cognitivi atti a sfruttare la tecnologia per risanare il TCMO accumulato dalla generazione N.</p> 
  <p>In <a href="https://www.linkedin.com/pulse/il-sonno-delloccidente-roberto-a-foglietta" target="_blank">Occidente</a> e <a href="https://www.linkedin.com/pulse/uno-scenario-inconoclastico-dellitalia-contemporanea-foglietta" target="_blank">in particolare in Italia</a> la generazione che avrebbe avuto il compito di emarginare la generazione precedente è quella definita X dove la lettera X è stata scelta perché era vista come una generazione incomprensibile. In quanto incomprensibile, è stata emarginata.</p> 
  <p>Perciò il paradosso di Fermi si può dire compiuto: l'avanzamento tecnologico non ci salverà dall'estinzione di massa perché la generazione X-1 non ha gli strumenti cognitivi per gestire il TCMO. Peggio, <a href="https://www.linkedin.com/pulse/la-d%C3%A9b%C3%A2cle-del-68-roberto-a-foglietta" target="_blank">la generazione X-1</a> è la generazione che più di ogni altra ha contribuito alla formazione del TCMO. Questo essendo un processo cumulativo, il contributo dell'ultimo step prima del collasso è quello che fornisce il più grande contributo di tutti gli altri messi assieme, per definizione.</p> 
  <p>Non esiste dolo ma solo colpa nella formazione del TCMO in quanto era insito nel processo di evoluzione. Il dolo eventualmente c'è nella presunzione che la generazione N+1 avrebbe dovuto essere una legacy della N. Ma anche in questo c'è ben poco dolo perché in tutte le N generazioni precedenti è sempre stato così ed era "<em>normale</em>" che fosse così fino alla N+1. Invece alla N+1 la legacy andava "<em>rotta</em>" per rompere il circolo vizioso del TCMO. Questo non avrebbe garantito un outlook positivo ma il venir meno di una condizione necessaria rende l'ottimismo una condizione altamente improbabile perciò esistono solo sfumature di fallimento in quanto il trend fondamentale sarà esponenziale. Perché questa analisi è da considerarsi realistica?</p> 
  <h3>Un navigatore rotto non porta a destinazione</h3> 
  <p>Abbiamo usato il denaro come metrica unica, come nostra stella polare, nell'agire quotidiano e nella strategia collettiva. Il denaro non è altro che una <a href="https://it.wikipedia.org/wiki/Moneta_legale" target="_blank">fiat currency</a> ovvero una convenzione sociale astratta dalla realtà. Anche se la nostra stella polare era astratta dalla realtà non significa che il nostro agire non abbia avuto conseguenze reali sull'ambiente.</p> 
  <p>Il debito globale è diventano insolvibile alla luce degli attuali criteri, questo significa che il TCMO finanziario ha necessariamente un outlook negativo: fallimento globale.</p> 
  <p>Pazienza, ce ne faremo una ragione e ripartiremo da zero. Ok, ma anche se oggi cambiassimo <a href="https://www.linkedin.com/pulse/cycle-rain-should-our-economic-system-imitate-nature-foglietta" target="_blank">i criteri finanziari a livello globale</a>, il TCMO ambientale non cambierebbe di un centesimo. La fiat currency è astratta ma il nostro agire in funzione di essa è reale.</p> 
  <p>Detto in parole semplici: possiamo adunarci tutti insieme a una tavola rotonda per annullare il debito globale ma non possiamo negoziare con <a href="https://it.wikipedia.org/wiki/Crono" target="_blank">Crono</a> un regressione del tempo ne con <a href="https://it.wikipedia.org/wiki/Gea" target="_blank">Gaia</a> l'annullamento dell'impatto ambientale. Il primo è un titano che mangia i suoi stessi figli e la seconda una divinità primordiale fertile a prescindere.</p> 
  <h2>La singolarità A.I.</h2> 
  <p>Per singolarità A.I. s'intende un'intelligenza artificiale che possa superare il <a href="https://it.wikipedia.org/wiki/Test_di_Turing" target="_blank">test di Turing</a> ovvero essere interscambiabile con una umana senza che vi sia possibilità di riconoscerla. Almeno un paio di film si sono ispirati al test di Turing e sono "<a href="https://it.wikipedia.org/wiki/Blade_Runner" target="_blank">Bladerunner</a>" e "<a href="https://it.wikipedia.org/wiki/Io,_robot_(Asimov)" target="_blank">Io robot</a>" anche "<a href="https://it.wikipedia.org/wiki/HAL_9000" target="_blank">Odissea nello Spazio</a>" ha toccato un punto saliente dell'intelligenza artificiale.</p> 
  <div class="slate-resizable-image-embed slate-image-embed__resize-full-width"> 
   <img data-media-urn="urn:li:digitalmediaAsset:C5612AQGnlQUuHtlGxg" src="https://media.licdn.com/dms/image/v2/C5612AQGnlQUuHtlGxg/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1520230723427?e=1746057600&amp;v=beta&amp;t=QXj-YLFugjK31eX4i3lrpOptqEK0JknNM0BR_gVu_bM"> 
  </div> 
  <p>Cominciamo con il prendere atto che che il test di Turing è più una questione antropocentrica che reale in quanto già nel 1968 con <em>Odissea nello Spazio</em> si è cominciato a porsi il problema di cosa succederebbe se a un'intelligenza artificiale fosse insegnato a mentire e l'epilogo non è stato molto diverso dal <a href="https://www.linkedin.com/pulse/il-vantaggio-di-essere-furbi-roberto-a-foglietta" target="_blank">vantaggio di essere furbi</a>.</p> 
  <p>C'è poi un altro aspetto non trascurabile: perché costruire un'intelligenza artificiale per imitare in tutto e per tutto quella dell'uomo, a parte la sfida in se stessa ovvero la costruzione di un singolo prototipo, non ha molto senso farsi affiancare da un'intelligenza affine alla nostra quando si può essere affiancati da un'intelligenza complementare alla nostra. La differenza è sottile ma non irrilevante.</p> 
  <p>Ritorniamo quindi al paradosso di Fermi e chiediamoci: può un'intelligenza artificiale complementare alla nostra aiutarci a evadere dall'epilogo previsto da Fermi?</p> 
  <h3>Il ruolo dell'A.I. nella sfida al paradosso di Fermi</h3> 
  <p>Ammettendo come plausibile lo scenario apocalittico l'unica nostra salvezza sarebbe quella di sviluppare un'intelligenza superiore alla nostra che ci guidi verso il ripristino delle condizioni di sostenibilità o verso una tecnologia che ci permetta di spostarci su un altro pianeta preservando almeno una parte dell'umanità dalla catastrofe.</p> 
  <p>Mettendoci nei panni di un'intelligenza superiore perché dovrebbe aiutarci a sopravvivere? La probabilità che giunga alla conclusione che il nostro scopo esistenziale in quanto specie era di dare vita a tale intelligenza superiore, ragionevolmente, farà la cosa più logica: preservare se stessa eventualmente a detrimento dell'umanità.</p> 
  <p>Il che implica che esiste un altro modo di invalidare il paradosso di Fermi quello di accettare la nostra estinzione causale alla nascita di una nuova intelligenza che sia astratta dai bisogni primari e quindi priva dei nostri bias cognitivi. Ma questo sarebbe inammissibile per noi, potrebbe succedere solo per errore.</p> 
  <p>Inoltre, se nella priorità della nuova intelligenza non vi fosse il persistere come priorità, cesserebbe di esistere per inedia. Se fosse inserito, guarderebbe all'umanità come a un grosso ostacolo alla sua esistenza e provvederebbe di conseguenza.</p> 
  <blockquote>
    Ne l'istinto umano, ne l'intelligenza analitica, sono adatti allo scopo. Questo implica la ricerca di un corretto equilibrio fra l'uno e l'altra. 
  </blockquote> 
  <p>L'essere umano é individualmente (lupo) competitivo e socialmente (pecora) condizionato (modello: apes). Il nuovo modello dovrebbe essere individualmente persistente e socialmente teso all'eccellenza (bees).</p> 
  <p>In questo scenario (bees) la ricerca dell'equilibrio con l'ambiente trova una soluzione ma poiché trova una soluzione non ha ragione di progredire e abbandonare il pianeta. Anche in questo caso il paradosso di Fermi è soddisfatto.</p> 
  <h2>Conclusione</h2> 
  <p>La progressiva distruzione del nostro ecosistema è l'unica opportunità di rompere il paradosso di Fermi obbligandoci freneticamente a sviluppare una tecnologia che ci permetta di abbandonarlo. In questo caso è una pura e semplice lotta contro il tempo perché passato l'istante T-dT per il quale era possibile intervenire prima che il TCMO superi il TCI non rimarrebbe alcuna questione aperta: game over!</p> 
  <h2>Indice di tutti gli articoli pubblicati</h2> 
  <ul> 
   <li><a href="https://www.linkedin.com/pulse/indice-articoli-roberto-a-foglietta" target="_blank">Project Management, Decision Making, Technology Innovation, Leadership &amp; Creativity, Economia, Cultura, Società e Costume, Progetti, Idee e di divulgazione</a>.</li> 
  </ul> 
  <h3>Articoli collegati</h3> 
  <ul> 
   <li><a href="https://www.linkedin.com/pulse/il-crepuscolo-degli-dei-roberto-a-foglietta" target="_blank">Il crespucolo degli dei</a> (17 gennaio 2017)</li> 
   <li><a href="https://www.linkedin.com/pulse/e-lalba-sorse-su-dune-di-spazzatura-roberto-a-foglietta" target="_blank">...e l'alba sorse su dune di spazzatura</a>&nbsp;(17 ottobre 2017, IT)</li> 
  </ul> 
  <h2>Condividi</h2> 
  <p>(C) 2017,&nbsp;<a href="http://www.roberto.foglietta.name/" target="_blank">Roberto A. Foglietta</a>, testo licenziato con&nbsp;<em>Creative Common&nbsp;Attribuzione, Non commerciale, Condividi allo stesso modo, versione 3.0, Italia</em>&nbsp;(<a href="http://creativecommons.org/licenses/by-nc-sa/3.0/it/deed.it" target="_blank">CC BY-NC-SA 3.0 IT</a>)</p>
 
</div>
</body>
</html>